#!/usr/bin/env python3
"""
ê°œì„ ëœ PDF ë²ˆì—­ê¸° V2 - 1ë‹¨ê³„ ê°œì„ ì‚¬í•­ ì ìš©
- ì¬ì‹œë„ íšŸìˆ˜: 2íšŒ â†’ 5íšŒ
- íƒ€ì„ì•„ì›ƒ: ë™ì  ì¡°ì • (í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜)
- None ê°’ ì²´í¬ ê°•í™”
- ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©
"""

import PyPDF2
import os
import json
import time
import re
import csv
import sys
from typing import List, Tuple, Optional, Dict
try:
    import openpyxl
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    from openpyxl.utils import get_column_letter
    OPENPYXL_AVAILABLE = True
except ImportError:
    OPENPYXL_AVAILABLE = False
    print("âš ï¸  openpyxl not installed. Excel output will be skipped.")

try:
    from toc_structure_parser import TOCStructureParser, TOCItem
    TOC_PARSER_AVAILABLE = True
except ImportError:
    TOC_PARSER_AVAILABLE = False

def extract_text_from_pdf(pdf_path: str, max_pages: Optional[int] = None) -> List[Tuple[int, str]]:
    """Extract text from PDF using PyPDF2"""
    pages_text = []
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)

            if max_pages:
                total_pages = min(total_pages, max_pages)

            print(f"ğŸ“– Extracting from {total_pages} pages...")

            for i in range(total_pages):
                try:
                    page = pdf_reader.pages[i]
                    text = page.extract_text()
                    if text and text.strip():
                        pages_text.append((i + 1, text.strip()))
                    else:
                        pages_text.append((i + 1, f"[Page {i + 1} - No extractable text]"))
                except Exception as e:
                    print(f"   âš ï¸  Error on page {i + 1}: {e}")
                    pages_text.append((i + 1, f"[Page {i + 1} - Extraction error: {str(e)}]"))

        print(f"âœ… Successfully processed {len(pages_text)} pages")
        return pages_text

    except Exception as e:
        print(f"âŒ Error reading PDF: {str(e)}")
        return []

def safe_text_cleaning(text: str) -> str:
    """Safely clean text with comprehensive error handling - IMPROVED"""
    if not text or not isinstance(text, str):
        return ""

    try:
        # Handle potential encoding issues
        if isinstance(text, bytes):
            text = text.decode('utf-8', errors='ignore')

        # ğŸ†• IMPROVED: More robust None checking
        if text is None or str(text).strip() == 'None':
            return ""

        # Split and filter out None/empty values
        clean_parts = []
        for part in str(text).split():
            # ğŸ†• IMPROVED: Stricter validation
            if part is not None and isinstance(part, str) and part.strip() and part.strip() != 'None':
                clean_parts.append(part.strip())

        if not clean_parts:
            return ""

        # Join safely
        clean_text = ' '.join(clean_parts)

        # Remove excessive formatting
        clean_text = re.sub(r'\.{3,}', '...', clean_text)
        clean_text = re.sub(r'\s+', ' ', clean_text)
        clean_text = clean_text.strip()

        return clean_text

    except Exception as e:
        print(f"      Text cleaning error: {e}")
        return ""

def extract_chinese_content(text: str) -> str:
    """Extract only Chinese characters and related content - IMPROVED"""
    try:
        # ğŸ†• IMPROVED: None check
        if text is None or not isinstance(text, str):
            return ""

        # Pattern for Chinese characters, parentheses, and common punctuation
        chinese_pattern = r'[\u4e00-\u9fff\u3400-\u4dbf\ï¼ˆ\ï¼‰\uff08\uff09A-Za-z0-9\s]+'
        matches = re.findall(chinese_pattern, text)

        if matches:
            # ğŸ†• IMPROVED: Filter None values
            matches = [m for m in matches if m is not None and str(m).strip()]
            if not matches:
                return ""

            chinese_text = ' '.join(matches)
            # Clean up excessive spaces
            chinese_text = re.sub(r'\s+', ' ', chinese_text).strip()
            return chinese_text
        return ""
    except Exception as e:
        print(f"      Chinese extraction error: {e}")
        return ""

def calculate_dynamic_timeout(text_length: int) -> int:
    """ğŸ†• NEW: Calculate timeout based on text length"""
    # Base timeout: 30 seconds
    # Add 10 seconds per 1000 characters
    # Maximum: 180 seconds (3 minutes)
    timeout = min(30 + (text_length // 100), 180)
    return timeout

def translate_with_google_robust(text: str) -> str:
    """ğŸ†• IMPROVED: Robust translation with enhanced retry mechanism"""
    try:
        from googletrans import Translator

        # Initial validation
        if not text or not isinstance(text, str):
            return "[Error: Invalid input]"

        # ğŸ†• IMPROVED: Stronger None check
        if text is None or str(text).strip() == 'None':
            return "[Error: None value detected]"

        # Clean text safely
        clean_text = safe_text_cleaning(text)
        if not clean_text:
            return "[Error: No valid text after cleaning]"

        # Check text length
        if len(clean_text) < 5:
            return f"[Skipped: Too short - '{clean_text}']"

        # ğŸ†• NEW: Calculate dynamic timeout
        text_length = len(clean_text)
        timeout = calculate_dynamic_timeout(text_length)
        print(f"      Text length: {text_length} chars, Timeout: {timeout}s")

        # Handle heavily formatted text (TOC pages)
        symbol_count = clean_text.count('.') + clean_text.count('-') + clean_text.count('_')
        symbol_ratio = symbol_count / len(clean_text) if len(clean_text) > 0 else 0

        if symbol_ratio > 0.25:  # More than 25% symbols
            print(f"      Detected TOC/formatted content...")
            chinese_content = extract_chinese_content(clean_text)
            if chinese_content and len(chinese_content) > 10:
                print(f"      Translating Chinese content: {chinese_content[:50]}...")

                # ğŸ†• IMPROVED: 5 attempts with exponential backoff for TOC
                for attempt in range(5):
                    try:
                        translator = Translator()
                        result = translator.translate(chinese_content, dest='en')

                        # ğŸ†• IMPROVED: Stronger validation
                        if result and hasattr(result, 'text') and result.text and result.text is not None:
                            return f"[TOC] {result.text}"
                        else:
                            print(f"      TOC attempt {attempt + 1}: Empty result")
                    except Exception as e:
                        print(f"      TOC attempt {attempt + 1} failed: {e}")
                        if attempt < 4:  # Don't wait after last attempt
                            wait_time = 2 ** attempt  # Exponential backoff: 1, 2, 4, 8, 16 seconds
                            print(f"      Waiting {wait_time}s before retry...")
                            time.sleep(wait_time)

                return f"[TOC - Translation failed after 5 attempts]"
            return f"[Skipped: Mostly formatting - {clean_text[:50]}...]"

        # Regular translation for normal content
        if len(clean_text) > 2000:  # ğŸ†• IMPROVED: Increased limit from 1500 to 2000
            print(f"      Text too long ({len(clean_text)} chars), truncating to 2000...")
            clean_text = clean_text[:2000] + "..."

        print(f"      Translating: {clean_text[:50]}...")

        # ğŸ†• IMPROVED: 5 attempts with exponential backoff
        for attempt in range(5):
            try:
                # Create new translator instance each time
                translator = Translator()
                result = translator.translate(clean_text, dest='en')

                # ğŸ†• IMPROVED: Stronger result validation
                if result and hasattr(result, 'text') and result.text and result.text is not None and str(result.text).strip():
                    print(f"      âœ… Success on attempt {attempt + 1}")
                    return result.text
                else:
                    print(f"      Attempt {attempt + 1}: Empty or None result")
            except Exception as e:
                print(f"      Attempt {attempt + 1} failed: {e}")

            # ğŸ†• IMPROVED: Exponential backoff
            if attempt < 4:  # Don't wait after last attempt
                wait_time = 2 ** attempt  # 1, 2, 4, 8, 16 seconds
                print(f"      Waiting {wait_time}s before retry...")
                time.sleep(wait_time)

        return f"[Translation failed after 5 attempts]"

    except ImportError:
        return "[Error: googletrans not installed]"
    except Exception as e:
        return f"[Translation error: {str(e)}]"

def load_failed_pages_from_json(json_path: str) -> List[int]:
    """Load list of failed page numbers from previous translation"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        failed_pages = []
        for page in data['pages']:
            translated = page['translated_text']
            if '[Translation failed' in translated or '[TOC -' in translated or 'NoneType' in translated:
                failed_pages.append(page['page_number'])

        return sorted(failed_pages)
    except Exception as e:
        print(f"Error loading failed pages: {e}")
        return []

def create_outputs(results: List[dict], base_name: str = "improved_translation_v2"):
    """Create both JSON and CSV outputs"""
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")

    # JSON output
    json_data = {
        "total_pages_processed": len(results),
        "timestamp": timestamp,
        "successful_translations": len([r for r in results if not r['translated_text'].startswith('[')]),
        "pages": results
    }

    json_file = f"output/{base_name}.json"
    try:
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSON saved: {json_file}")
    except Exception as e:
        print(f"âŒ JSON save error: {e}")

    # CSV output
    csv_file = f"output/{base_name}.csv"
    try:
        with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['Page', 'Original_Sample', 'Translation', 'Original_Length', 'Translation_Length', 'Status']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            writer.writeheader()
            for result in results:
                status = "Success" if not result['translated_text'].startswith('[') else "Processed"
                writer.writerow({
                    'Page': result['page_number'],
                    'Original_Sample': result['original_text'][:200] + '...' if len(result['original_text']) > 200 else result['original_text'],
                    'Translation': result['translated_text'][:200] + '...' if len(result['translated_text']) > 200 else result['translated_text'],
                    'Original_Length': result['original_char_count'],
                    'Translation_Length': result['translated_char_count'],
                    'Status': status
                })
        print(f"âœ… CSV saved: {csv_file}")
    except Exception as e:
        print(f"âŒ CSV save error: {e}")

    # Excel output (ì½ê¸° ì¢‹ì€ ë²„ì „)
    if OPENPYXL_AVAILABLE:
        excel_file = f"output/{base_name}_readable.xlsx"
        try:
            # êµ¬ì¡°í™” ì˜µì…˜ í™•ì¸
            use_structure = '--structure' in sys.argv or '--toc' in sys.argv
            if use_structure and TOC_PARSER_AVAILABLE:
                print("   ğŸ“Š ëª©ì°¨ êµ¬ì¡° ê¸°ë°˜ ì •ë¦¬ í™œì„±í™”")
                create_structured_excel(json_data, excel_file)
            else:
                create_readable_excel(json_data, excel_file)
        except Exception as e:
            print(f"âŒ Excel save error: {e}")
    else:
        print("âš ï¸  Excel output skipped (openpyxl not installed)")

def create_readable_excel(data: dict, output_path: str):
    """ì½ê¸° ì¢‹ì€ Excel íŒŒì¼ ìƒì„± (ì¤„ë°”ê¿ˆ, í•œì ì™„ë²½ í‘œì‹œ)"""
    wb = openpyxl.Workbook()

    # ì‹œíŠ¸ 1: í†µê³„
    ws_stats = wb.active
    ws_stats.title = "ğŸ“Š í†µê³„"

    # ì œëª©
    ws_stats['A1'] = "ğŸ“Š ë²ˆì—­ ê²°ê³¼ í†µê³„"
    ws_stats['A1'].font = Font(bold=True, size=16)
    ws_stats.merge_cells('A1:B1')

    # í†µê³„ ë°ì´í„°
    stats = [
        ("", ""),
        ("ì´ í˜ì´ì§€ ìˆ˜", data['total_pages_processed']),
        ("ì„±ê³µí•œ ë²ˆì—­", data['successful_translations']),
        ("ì‹¤íŒ¨/ì²˜ë¦¬", data['total_pages_processed'] - data['successful_translations']),
        ("ì„±ê³µë¥ ", f"{data['successful_translations']/data['total_pages_processed']*100:.1f}%"),
        ("ì²˜ë¦¬ ì‹œê°„", data.get('timestamp', 'N/A')),
    ]

    row = 2
    for label, value in stats:
        ws_stats[f'A{row}'] = label
        ws_stats[f'B{row}'] = value

        if label:
            ws_stats[f'A{row}'].font = Font(bold=True)
            ws_stats[f'A{row}'].fill = PatternFill(start_color="E7E6E6", end_color="E7E6E6", fill_type="solid")
        row += 1

    ws_stats.column_dimensions['A'].width = 20
    ws_stats.column_dimensions['B'].width = 30

    # ì‹œíŠ¸ 2: ì „ì²´ ë²ˆì—­ ê²°ê³¼
    ws_all = wb.create_sheet("ğŸ“„ ì „ì²´ í˜ì´ì§€")
    create_translation_sheet(ws_all, data['pages'])

    # ì‹œíŠ¸ 3: ì„±ê³µë§Œ
    successful = [p for p in data['pages'] if not p['translated_text'].startswith('[')]
    if successful:
        ws_success = wb.create_sheet("âœ… ì„±ê³µ")
        create_translation_sheet(ws_success, successful)

    # ì‹œíŠ¸ 4: ì‹¤íŒ¨/ì²˜ë¦¬ í•„ìš”
    failed = [p for p in data['pages'] if p['translated_text'].startswith('[')]
    if failed:
        ws_failed = wb.create_sheet("âš ï¸ ì‹¤íŒ¨")
        create_translation_sheet(ws_failed, failed)

    wb.save(output_path)
    print(f"âœ… Excel saved (ì½ê¸° ì¢‹ì€ ë²„ì „): {output_path}")

def create_translation_sheet(ws, pages):
    """ë²ˆì—­ ê²°ê³¼ ì‹œíŠ¸ ìƒì„± (ì¤„ë°”ê¿ˆ ìë™ í‘œì‹œ)"""
    # í—¤ë”
    headers = ['í˜ì´ì§€', 'ì›ë¬¸', 'ë²ˆì—­ë¬¸', 'ì›ë¬¸ ê¸¸ì´', 'ë²ˆì—­ë¬¸ ê¸¸ì´', 'ìƒíƒœ', 'ì‹œê°„(ì´ˆ)']

    # í—¤ë” ìŠ¤íƒ€ì¼
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(bold=True, color="FFFFFF", size=11)

    for col, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col)
        cell.value = header
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = Alignment(horizontal="center", vertical="center")

    # í…Œë‘ë¦¬ ìŠ¤íƒ€ì¼
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )

    # ë°ì´í„° ì‘ì„±
    for row_idx, page in enumerate(pages, 2):
        is_success = not page['translated_text'].startswith('[')
        status = "âœ… ì„±ê³µ" if is_success else "âš ï¸ ì‹¤íŒ¨"

        # ì…€ ê°’ ì„¤ì •
        ws.cell(row=row_idx, column=1, value=page['page_number'])
        ws.cell(row=row_idx, column=2, value=page['original_text'][:500])  # ì›ë¬¸
        ws.cell(row=row_idx, column=3, value=page['translated_text'][:500])  # ë²ˆì—­ë¬¸
        ws.cell(row=row_idx, column=4, value=page['original_char_count'])
        ws.cell(row=row_idx, column=5, value=page['translated_char_count'])
        ws.cell(row=row_idx, column=6, value=status)
        ws.cell(row=row_idx, column=7, value=page.get('translation_time', 'N/A'))

        # ìŠ¤íƒ€ì¼ ì ìš©
        for col in range(1, 8):
            cell = ws.cell(row=row_idx, column=col)
            cell.border = thin_border

            # â­ í…ìŠ¤íŠ¸ ë˜í•‘ (ì¤„ë°”ê¿ˆ í‘œì‹œ)
            if col in [2, 3]:
                cell.alignment = Alignment(wrap_text=True, vertical="top")
            else:
                cell.alignment = Alignment(horizontal="center", vertical="center")

        # ì„±ê³µ/ì‹¤íŒ¨ ìƒ‰ìƒ
        status_cell = ws.cell(row=row_idx, column=6)
        if is_success:
            status_cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
        else:
            status_cell.fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

    # ì—´ ë„ˆë¹„ ì¡°ì •
    ws.column_dimensions['A'].width = 8
    ws.column_dimensions['B'].width = 60   # ì›ë¬¸ (ë„“ê²Œ)
    ws.column_dimensions['C'].width = 60   # ë²ˆì—­ë¬¸ (ë„“ê²Œ)
    ws.column_dimensions['D'].width = 12
    ws.column_dimensions['E'].width = 12
    ws.column_dimensions['F'].width = 12
    ws.column_dimensions['G'].width = 10

    # í–‰ ë†’ì´ (ì¤„ë°”ê¿ˆ ê³ ë ¤)
    for row in range(2, len(pages) + 2):
        ws.row_dimensions[row].height = 100  # ì¶©ë¶„í•œ ë†’ì´

def create_structured_excel(data: dict, output_path: str):
    """ëª©ì°¨ êµ¬ì¡° ê¸°ë°˜ Excel íŒŒì¼ ìƒì„±"""
    parser = TOCStructureParser()
    wb = openpyxl.Workbook()

    # ëª©ì°¨ ì¶”ì¶œ (TOC í˜ì´ì§€ ì°¾ê¸°)
    toc_pages = [p for p in data['pages'] if p['page_number'] in [2, 3]]  # ì¼ë°˜ì ìœ¼ë¡œ 2-3í˜ì´ì§€
    toc_text = '\n'.join([p['original_text'] for p in toc_pages])

    # ëª©ì°¨ íŒŒì‹±
    toc_items = parser.parse_toc_text(toc_text)
    print(f"   ğŸ“– ëª©ì°¨ í•­ëª© {len(toc_items)}ê°œ ê°ì§€")

    # í˜ì´ì§€-ì„¹ì…˜ ë§¤í•‘ (ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”)
    debug_mode = '--debug' in sys.argv
    page_to_section = parser.map_pages_to_sections(data['pages'], debug=debug_mode)

    # ì‹œíŠ¸ 1: í†µê³„
    ws_stats = wb.active
    ws_stats.title = "ğŸ“Š í†µê³„"
    ws_stats['A1'] = "ğŸ“Š ë²ˆì—­ ê²°ê³¼ í†µê³„ (êµ¬ì¡°í™”)"
    ws_stats['A1'].font = Font(bold=True, size=16)
    ws_stats.merge_cells('A1:B1')

    stats = [
        ("", ""),
        ("ì´ í˜ì´ì§€ ìˆ˜", data['total_pages_processed']),
        ("ì„±ê³µí•œ ë²ˆì—­", data['successful_translations']),
        ("ëª©ì°¨ í•­ëª© ìˆ˜", len(toc_items)),
        ("ì„±ê³µë¥ ", f"{data['successful_translations']/data['total_pages_processed']*100:.1f}%"),
    ]

    row = 2
    for label, value in stats:
        ws_stats[f'A{row}'] = label
        ws_stats[f'B{row}'] = value
        if label:
            ws_stats[f'A{row}'].font = Font(bold=True)
            ws_stats[f'A{row}'].fill = PatternFill(start_color="E7E6E6", end_color="E7E6E6", fill_type="solid")
        row += 1

    ws_stats.column_dimensions['A'].width = 20
    ws_stats.column_dimensions['B'].width = 30

    # ì‹œíŠ¸ 2: êµ¬ì¡°í™”ëœ ë²ˆì—­ ê²°ê³¼
    ws_structured = wb.create_sheet("ğŸ“š êµ¬ì¡°í™”ëœ ë²ˆì—­")
    create_structured_translation_sheet(ws_structured, data['pages'], page_to_section, parser)

    # ì‹œíŠ¸ 3: ëª©ì°¨
    ws_toc = wb.create_sheet("ğŸ“‘ ëª©ì°¨")
    create_toc_sheet(ws_toc, toc_items)

    wb.save(output_path)
    print(f"âœ… Excel saved (êµ¬ì¡°í™” ë²„ì „): {output_path}")

def create_structured_translation_sheet(ws, pages, page_to_section: Dict, parser: TOCStructureParser):
    """êµ¬ì¡°í™”ëœ ë²ˆì—­ ì‹œíŠ¸"""
    headers = ['ì„¹ì…˜', 'í˜ì´ì§€', 'ì›ë¬¸', 'ë²ˆì—­ë¬¸', 'ìƒíƒœ']

    # í—¤ë” ìŠ¤íƒ€ì¼
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(bold=True, color="FFFFFF", size=11)

    for col, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col)
        cell.value = header
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = Alignment(horizontal="center", vertical="center")

    # í…Œë‘ë¦¬
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )

    # ì„¹ì…˜ë³„ë¡œ ê·¸ë£¹í™”
    current_section = None
    row_idx = 2

    for page in sorted(pages, key=lambda x: x['page_number']):
        page_num = page['page_number']
        section_num = page_to_section.get(page_num, "")

        # ìƒˆ ì„¹ì…˜ ì‹œì‘ ì‹œ í—¤ë” ì¶”ê°€
        if section_num and section_num != current_section:
            current_section = section_num
            section_info = parser.get_section_info(section_num)

            # ì„¹ì…˜ í—¤ë” í–‰
            level = section_num.count('.') + 1
            indent = "  " * (level - 1)
            section_title = f"{indent}{section_num}"
            if section_info:
                section_title += f" {section_info.title}"

            ws.cell(row=row_idx, column=1, value=section_title)
            ws.merge_cells(f'A{row_idx}:E{row_idx}')

            header_cell = ws.cell(row=row_idx, column=1)
            if level == 1:
                header_cell.fill = PatternFill(start_color="BDD7EE", end_color="BDD7EE", fill_type="solid")
                header_cell.font = Font(bold=True, size=12)
            elif level == 2:
                header_cell.fill = PatternFill(start_color="DDEBF7", end_color="DDEBF7", fill_type="solid")
                header_cell.font = Font(bold=True, size=11)
            else:
                header_cell.fill = PatternFill(start_color="E7E6E6", end_color="E7E6E6", fill_type="solid")
                header_cell.font = Font(bold=True, size=10)

            row_idx += 1

        # í˜ì´ì§€ ë°ì´í„°
        is_success = not page['translated_text'].startswith('[')
        status = "âœ…" if is_success else "âš ï¸"

        ws.cell(row=row_idx, column=1, value=section_num)
        ws.cell(row=row_idx, column=2, value=page_num)
        ws.cell(row=row_idx, column=3, value=page['original_text'][:300])
        ws.cell(row=row_idx, column=4, value=page['translated_text'][:300])
        ws.cell(row=row_idx, column=5, value=status)

        # ìŠ¤íƒ€ì¼
        for col in range(1, 6):
            cell = ws.cell(row=row_idx, column=col)
            cell.border = thin_border
            if col in [3, 4]:
                cell.alignment = Alignment(wrap_text=True, vertical="top")
            else:
                cell.alignment = Alignment(horizontal="center", vertical="center")

        if is_success:
            ws.cell(row=row_idx, column=5).fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")

        ws.row_dimensions[row_idx].height = 60
        row_idx += 1

    # ì—´ ë„ˆë¹„
    ws.column_dimensions['A'].width = 15
    ws.column_dimensions['B'].width = 8
    ws.column_dimensions['C'].width = 50
    ws.column_dimensions['D'].width = 50
    ws.column_dimensions['E'].width = 8

def create_toc_sheet(ws, toc_items: List[TOCItem]):
    """ëª©ì°¨ ì‹œíŠ¸"""
    headers = ['ë²ˆí˜¸', 'ì œëª©', 'ë ˆë²¨', 'í˜ì´ì§€']

    # í—¤ë”
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(bold=True, color="FFFFFF", size=11)

    for col, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col)
        cell.value = header
        cell.font = header_font
        cell.fill = header_fill
        cell.alignment = Alignment(horizontal="center", vertical="center")

    # ëª©ì°¨ í•­ëª©
    for row_idx, item in enumerate(toc_items, 2):
        indent = "  " * (item.level - 1)

        ws.cell(row=row_idx, column=1, value=item.number)
        ws.cell(row=row_idx, column=2, value=f"{indent}{item.title}")
        ws.cell(row=row_idx, column=3, value=item.level)
        ws.cell(row=row_idx, column=4, value=item.page)

        # ë ˆë²¨ë³„ ìƒ‰ìƒ
        if item.level == 1:
            fill = PatternFill(start_color="BDD7EE", end_color="BDD7EE", fill_type="solid")
        elif item.level == 2:
            fill = PatternFill(start_color="DDEBF7", end_color="DDEBF7", fill_type="solid")
        else:
            fill = PatternFill(start_color="F2F2F2", end_color="F2F2F2", fill_type="solid")

        ws.cell(row=row_idx, column=1).fill = fill
        ws.cell(row=row_idx, column=2).fill = fill

    # ì—´ ë„ˆë¹„
    ws.column_dimensions['A'].width = 12
    ws.column_dimensions['B'].width = 50
    ws.column_dimensions['C'].width = 8
    ws.column_dimensions['D'].width = 10

def main():
    """Main translation workflow - Re-translate only failed pages"""
    pdf_file = "input/XY-A ATSå¼€å‘å¯¹IBCéœ€æ±‚æ–‡æ¡£_V0.0.pdf"
    previous_results_json = "output/final_translation_results.json"

    # ëª…ë ¹ì¤„ ì˜µì…˜ í™•ì¸
    use_structure = '--structure' in sys.argv or '--toc' in sys.argv

    print("ğŸš€ ê°œì„ ëœ PDF ë²ˆì—­ê¸° V2 - 1ë‹¨ê³„ ê°œì„ ì‚¬í•­ ì ìš©")
    print("="*80)
    print("âœ¨ ê°œì„ ì‚¬í•­:")
    print("   1. ì¬ì‹œë„ íšŸìˆ˜: 2íšŒ â†’ 5íšŒ")
    print("   2. ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©: 1s, 2s, 4s, 8s, 16s")
    print("   3. íƒ€ì„ì•„ì›ƒ ë™ì  ì¡°ì •: 30-180ì´ˆ (í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜)")
    print("   4. None ê°’ ì²´í¬ ê°•í™”")
    print("   5. í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ: 1500ì â†’ 2000ì")
    if use_structure:
        print("   ğŸ“Š ëª©ì°¨ êµ¬ì¡° ê¸°ë°˜ ì •ë¦¬: í™œì„±í™”")
    print("="*80)

    # Check PDF existence
    if not os.path.exists(pdf_file):
        print(f"âŒ PDF not found: {pdf_file}")
        return

    print(f"\nâœ… Found PDF: {pdf_file}")

    # Load failed pages from previous translation
    print(f"\nğŸ“‚ Loading previous translation results...")
    failed_pages = load_failed_pages_from_json(previous_results_json)

    if not failed_pages:
        print("âŒ No failed pages found or couldn't load previous results")
        print("   Will translate all pages instead...")
        failed_pages = None
    else:
        print(f"âœ… Found {len(failed_pages)} failed pages to retry:")
        print(f"   Pages: {', '.join(map(str, failed_pages[:10]))}" +
              (f" ... (and {len(failed_pages)-10} more)" if len(failed_pages) > 10 else ""))

    # Extract text from PDF
    pages_text = extract_text_from_pdf(pdf_file, max_pages=None)

    if not pages_text:
        print("âŒ No text extracted from PDF")
        return

    # Filter to only failed pages if available
    if failed_pages:
        pages_to_translate = [(num, text) for num, text in pages_text if num in failed_pages]
        print(f"\nğŸ“‹ Retrying {len(pages_to_translate)} failed pages...")
    else:
        pages_to_translate = pages_text
        print(f"\nğŸ“‹ Translating all {len(pages_to_translate)} pages...")

    # Process translations
    results = []
    total_pages = len(pages_to_translate)

    for i, (page_num, text) in enumerate(pages_to_translate, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ“‹ Processing Page {page_num} ({i}/{total_pages})...")

        # Show sample of original
        sample = safe_text_cleaning(text)[:100]
        print(f"   ğŸ“ Original sample: {sample}...")

        # Translate
        print("   ğŸ”„ Translating with improved retry mechanism...")
        start_time = time.time()
        translated_text = translate_with_google_robust(text)
        translation_time = time.time() - start_time

        # Show result sample
        result_sample = translated_text[:100]
        print(f"   âœ… Result: {result_sample}...")
        print(f"   â±ï¸  Time: {translation_time:.1f}s")

        # Determine status
        if translated_text.startswith('['):
            print(f"   âš ï¸  Status: FAILED/PROCESSED")
        else:
            print(f"   âœ… Status: SUCCESS")

        results.append({
            "page_number": page_num,
            "original_text": text,
            "translated_text": translated_text,
            "original_char_count": len(text),
            "translated_char_count": len(translated_text),
            "translation_time": round(translation_time, 2)
        })

        # Rate limiting - longer wait between pages
        if i < total_pages:
            wait_time = 2  # ğŸ†• IMPROVED: Increased from 1.5s to 2s
            print(f"   â³ Waiting {wait_time}s before next page...")
            time.sleep(wait_time)

    # Save results
    print(f"\n{'='*80}")
    print(f"ğŸ’¾ Saving results...")
    create_outputs(results, "improved_translation_v2_results")

    # Summary
    successful = len([r for r in results if not r['translated_text'].startswith('[')])
    processed = len([r for r in results if r['translated_text'].startswith('[TOC]')])
    failed = len(results) - successful - processed

    print(f"\nğŸ“Š Final Summary:")
    print(f"   ğŸ“„ Total pages processed: {len(results)}")
    print(f"   âœ… Successful translations: {successful} ({successful/len(results)*100:.1f}%)")
    print(f"   ğŸ“‹ Processed (TOC/formatted): {processed}")
    print(f"   âŒ Failed/skipped: {failed} ({failed/len(results)*100:.1f}%)")

    # Improvement comparison
    if failed_pages:
        previous_failed = len(failed_pages)
        new_successful = successful
        improvement = new_successful
        print(f"\nğŸ“ˆ Improvement Analysis:")
        print(f"   ğŸ”´ Previously failed: {previous_failed} pages")
        print(f"   ğŸŸ¢ Now successful: {new_successful} pages ({new_successful/previous_failed*100:.1f}%)")
        print(f"   ğŸ“Š Improvement: {improvement} pages recovered")
        if failed > 0:
            print(f"   ğŸ”´ Still failing: {failed} pages ({failed/previous_failed*100:.1f}%)")

    # Show best samples
    if successful > 0:
        best_results = [r for r in results if not r['translated_text'].startswith('[')]
        if best_results:
            sample = best_results[0]
            print(f"\nğŸ† Sample Translation (Page {sample['page_number']}):")
            print("ğŸ‡¨ğŸ‡³ Original:")
            print("  " + sample['original_text'][:150].replace('\n', ' ') + "...")
            print("ğŸ‡ºğŸ‡¸ Translation:")
            print("  " + sample['translated_text'][:150] + "...")

    print("\nâœ… Translation completed successfully!")
    print("ğŸ“ Check the output files for complete results.")

if __name__ == "__main__":
    main()
